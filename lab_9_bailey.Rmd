---
title: "lab_9_bailey"
author: "Allison Bailey"
date: "3/5/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)
```

```{r}
library(tidyverse)
library(here)
library(boot)
library(gt)
library(patchwork)
library(broom)
library(nlstools)
```


### Fun tables with 'gt'

LifeCycleSavings (see?LifeCycleSavings if you want to see more)

```{r}

disp_income <- LifeCycleSavings %>%
  rownames_to_column() %>%
  arrange(dpi) %>%
  head(5) %>%
  mutate(ddpi = ddpi / 100,
         pop15 = pop15 / 100,
         pop75 = pop75 / 100)

```

Now let's make a nicer table with the gt package:


```{r}
disp_income %>%
  gt() %>%
  tab_header(
    title = "Life cycle savings",
    subtitle = "5 countries with lowest per capita disposable income"
  ) %>%
  fmt_currency(
    columns = vars(dpi),
    decimals = 2,
  ) %>%
  fmt_percent(
    columns = vars(pop15, pop75, ddpi),
    decimals = 1
  ) %>%
  tab_options(
    table.width = pct(80)
  ) %>%
  tab_footnote(
    footnote = "Data averaged from 1970 - 1980",
    location = cells_title()
  ) %>%
  data_color(
    columns = vars(dpi),
    colors = scales::col_numeric(
      palette = c("orange", "red", "purple"),
      domain = c(88, 190)
    )
  ) %>%
  cols_label(
    sr = "Savings ratio"
  )

```

### Bootstrap the confidence nterval for salinity

```{r}


 hist(salinity$sal)

ggplot(data = salinity, aes(sample = sal)) +
  geom_qq()

# I believe based on a single sample of n = 28 that a t-distribution describes the sampling distribution!
t.test(salinity$sal)
```
Create a funciton to calculate the mean of different bootstrap samples:

```{r}
mean_fun <- function(x, i) {mean(x[i])}

sal_nc <- salinity$sal

salboot_100 <- boot(data = sal_nc,
                    statistic = mean_fun,
                    R = 100)

salboot_10k <- boot(data = sal_nc,
                    statistic = mean_fun,
                    R = 10000)

salboot_100_df <- data.frame(bs_mean = salboot_100$t)
salboot_10k_df <- data.frame(bs_mean = salboot_10k$t)

# Now let's plot the bootstrapped sampling dstribution

p1 <- ggplot(data = salinity, aes(x = sal)) +
  geom_histogram()
p1

p2 <- ggplot(data = salboot_100_df, aes(x = bs_mean)) +
  geom_histogram()
p2

p3 <- ggplot(data = salboot_10k_df, aes(x = bs_mean)) +
  geom_histogram()

p3

# Using 'patchwork':
p1 + p2 + p3

p1 + p2 / p3

(p1 +p2) / p3


```


```{r}
boot.ci(salboot_10k, conf = 0.95)
```


```{r}
df <- read_csv(here("data", "log_growth.csv"))
               
df

df_exp <- df %>%
  filter(time<15) %>%
  mutate(ln_pop = log(pop))

lm_k <- lm(ln_pop ~ time, data = df_exp)
```

```{r}
df_nls <- nls(pop ~ K/(1 + A*exp(-r*time)),
data = df, 
start = list(K = 180, A = 18, r = 0.17),
trace = TRUE)

model_out <- broom::tidy(df_nls)
model_out
```

```{r}
t_seq <- seq(from = 0, to = 35, length = 200)

# Now make predictions from our NLS model, using that new sequence of times:
p_predict <- predict(df_nls, newdata = t_seq)

# Bind together my time and prediciton data:
df_complete <- data.frame(df, p_predict)

ggplot(data = df_complete, aes(x = time, y = pop)) +
  geom_point() +
  geom_line(aes(x = time, y = p_predict)) +
  theme_minimal()

df_complete

```

```{r}

df_ci <- confint2(df_nls)
df_ci

```

